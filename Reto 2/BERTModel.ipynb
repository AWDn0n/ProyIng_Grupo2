{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import DistilBertTokenizerFast\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import load_dataset\n",
    "#imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imdb['train']['text'][2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i really do recommend this to anyone in need o...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>very good every day camera fits nicely in the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>but , dollar for dollar , this dvd player is p...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i got this phone yesterday and didn ' t find a...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1 ) price gb of storage</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_idx                                               text  label  \\\n",
       "0          0  i really do recommend this to anyone in need o...      1   \n",
       "1          1  very good every day camera fits nicely in the ...      1   \n",
       "2          2  but , dollar for dollar , this dvd player is p...      1   \n",
       "3          3  i got this phone yesterday and didn ' t find a...      1   \n",
       "4          4                            1 ) price gb of storage      1   \n",
       "\n",
       "  label_text  \n",
       "0   positive  \n",
       "1   positive  \n",
       "2   positive  \n",
       "3   positive  \n",
       "4   positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_idx     0\n",
       "text          0\n",
       "label         0\n",
       "label_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_idx                                                  1611\n",
       "text          exposure compensation in 1 3 stop increments (...\n",
       "label                                                         1\n",
       "label_text                                             positive\n",
       "Name: 1611, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[1611]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposure compensation in 1 3 stop increments ( i leave it set on 1 3 stop to brighten up the default exposure , which goes a bit dark for my taste )\n"
     ]
    }
   ],
   "source": [
    "# show row 1611\n",
    "print(train[train['train_idx'] == 1611].text.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"negative\", 1: \"positive\"}\n",
    "label2id = {\"negative\": 0, \"positive\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    1926\n",
       "negative    1090\n",
       "Name: label_text, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label_text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_split, val_split = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1611</td>\n",
       "      <td>exposure compensation in 1 3 stop increments (...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train_idx                                               text  label  \\\n",
       "1611       1611  exposure compensation in 1 3 stop increments (...      1   \n",
       "\n",
       "     label_text  \n",
       "1611   positive  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split[train_split['train_idx'] == 1611]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform data to correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext.legacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchtext\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m Field, TabularDataset, BucketIterator\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext.legacy'"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy import Field, TabularDataset, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__all__\n",
      "__builtins__\n",
      "__cached__\n",
      "__doc__\n",
      "__file__\n",
      "__loader__\n",
      "__name__\n",
      "__package__\n",
      "__path__\n",
      "__spec__\n",
      "bleu_score\n",
      "custom_replace\n",
      "datasets_utils\n",
      "filter_wikipedia_xml\n",
      "functional\n",
      "generate_sp_model\n",
      "get_tokenizer\n",
      "interleave_keys\n",
      "load_sp_model\n",
      "metrics\n",
      "numericalize_tokens_from_iterator\n",
      "sentencepiece_numericalizer\n",
      "sentencepiece_tokenizer\n",
      "simple_space_split\n",
      "to_map_style_dataset\n",
      "utils\n"
     ]
    }
   ],
   "source": [
    "# show contents of module torchtext.data\n",
    "print(*(dir(torchtext.data)),sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'are',\n",
       " 'as',\n",
       " 'duplicated',\n",
       " 'is',\n",
       " 'like',\n",
       " 'such',\n",
       " 'test',\n",
       " 'this',\n",
       " 'where',\n",
       " 'words'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set('this is a a test where words such as test are duplicated like this test'.split())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Load model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pytorch g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this device might need to be changed to 'cpu' if you're not using a GPU or apple silicon\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return tokenizer.encode_plus(text, \n",
    "                                  add_special_tokens=True, \n",
    "                                  padding=True, \n",
    "                                  return_attention_mask=True, \n",
    "                                  return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 3231,  102]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_split['text'].tolist()\n",
    "train_encodings = tokenizer.batch_encode_plus(train_texts, \n",
    "                                              add_special_tokens=True, \n",
    "                                              padding='longest', \n",
    "                                              return_attention_mask=True, \n",
    "                                              return_tensors='pt')\n",
    "train_labels = torch.tensor(train_split['label'].tolist())\n",
    "\n",
    "val_texts = val_split['text'].tolist()\n",
    "val_encodings = tokenizer.batch_encode_plus(val_texts, \n",
    "                                            add_special_tokens=True, \n",
    "                                            padding='longest', \n",
    "                                            return_attention_mask=True, \n",
    "                                            return_tensors='pt')\n",
    "val_labels = torch.tensor(val_split['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 2e-5\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_encodings['input_ids'], \n",
    "                              train_encodings['attention_mask'], \n",
    "                              train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], \n",
    "                            val_encodings['attention_mask'], \n",
    "                            val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_split, batch_size=16, shuffle=True)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_acc= 0., 0.\n",
    "\n",
    "    for batch in val_loader:\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss += outputs.loss.item()\n",
    "            val_acc += (outputs.logits.argmax(dim=1) == labels).float().sum().item()\n",
    "            \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc /= len(val_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - val_loss: {val_loss:.4f}, val_acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1659",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1659",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m error_indices \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      4\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBatch #\u001b[39m\u001b[39m\"\u001b[39m, batch_idx)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1659"
     ]
    }
   ],
   "source": [
    "error_indices = []\n",
    "\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "    try:\n",
    "        print(\"Batch #\", batch_idx)\n",
    "        print(\"Input ids shape:\", batch['input_ids'].shape)\n",
    "        print(\"Attention mask shape:\", batch['attention_mask'].shape)\n",
    "        print(\"Labels shape:\", batch['labels'].shape)\n",
    "    except:\n",
    "        error_indices.append(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1380",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1380",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      2\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m         \u001b[39mprint\u001b[39m(batch[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1380"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    try:\n",
    "        print(batch['input_ids'].shape)\n",
    "    except:\n",
    "        print('ffs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'just the home version of norton internet av has too many glitches and problems to even remotely bother with'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['train_idx'] == 1380]['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'just the home version of norton internet av has too many glitches and problems to even remotely bother with'\n",
    "text = str(text)\n",
    "encoded_dict = tokenizer.encode_plus(text, max_length=128, padding='max_length', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2074,  1996,  2188,  2544,  1997, 10770,  4274, 20704,  2038,\n",
       "          2205,  2116,  1043, 15909,  8376,  1998,  3471,  2000,  2130, 19512,\n",
       "          8572,  2007,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict['input_ids']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model_name = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1996, 8278, 2165, 1037, 2210, 2893, 2109, 2000, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': [101, 3866, 1996, 11754, 2640, 102], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(train_split.iterrows()):\n",
    "    print(preprocess_function(x[1]))\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [preprocess_function(row[1]) for row in train_split.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_val = [preprocess_function(row[1]) for row in val_split.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = evaluate.load(\"accuracy\")\n",
    "   load_f1 = evaluate.load(\"f1\")\n",
    "   metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   clf_metrics = metrics.compute(predictions=predictions, references=labels)\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"imgonnacry\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ismael/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f72caf00b0d4daab3ed557073750b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/transformers/trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1632\u001b[0m )\n\u001b[0;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1638\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/transformers/trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1900\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1901\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1902\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1905\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1906\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1907\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1908\u001b[0m ):\n\u001b[1;32m   1909\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/transformers/trainer.py:2645\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2642\u001b[0m     \u001b[39mreturn\u001b[39;00m loss_mb\u001b[39m.\u001b[39mreduce_mean()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m   2644\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2645\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs)\n\u001b[1;32m   2647\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mn_gpu \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2648\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()  \u001b[39m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/ViT/lib/python3.9/site-packages/transformers/trainer.py:2690\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2688\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2689\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m outputs:\n\u001b[0;32m-> 2690\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2691\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2692\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(outputs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m. For reference, the inputs it received are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(inputs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2693\u001b[0m         )\n\u001b[1;32m   2694\u001b[0m     \u001b[39m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[1;32m   2695\u001b[0m     loss \u001b[39m=\u001b[39m outputs[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ViT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
