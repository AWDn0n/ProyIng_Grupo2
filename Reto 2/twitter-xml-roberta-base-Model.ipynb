{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBARIES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from scipy.special import softmax\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i really do recommend this to anyone in need o...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>very good every day camera fits nicely in the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>but , dollar for dollar , this dvd player is p...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_idx                                               text  label  \\\n",
       "0          0  i really do recommend this to anyone in need o...      1   \n",
       "1          1  very good every day camera fits nicely in the ...      1   \n",
       "2          2  but , dollar for dollar , this dvd player is p...      1   \n",
       "\n",
       "  label_text  \n",
       "0   positive  \n",
       "1   positive  \n",
       "2   positive  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fm receiver it has none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the picture quality surprised me , when i firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>great video clip quality for a digital camera ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_idx                                               text\n",
       "0         0                            fm receiver it has none\n",
       "1         1  the picture quality surprised me , when i firs...\n",
       "2         2  great video clip quality for a digital camera ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_idx     0\n",
       "text          0\n",
       "label         0\n",
       "label_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any colulumn has null values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_idx    0\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1926\n",
       "0    1090\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"label\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the panorama setting is unbelievable ! \n",
      " [{'label': 'positive', 'score': 0.5229542851448059}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)\n",
    "print(test['text'][np.random.randint(0, len(test))], \"\\n\", sentiment_task(test['text'][np.random.randint(0, len(test))]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/22021108Cristina/.cache/huggingface/datasets/csv/default-7e50772f604fcc87/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31edaebef45f4afaadece52afa2af8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train = load_dataset('csv', data_files='data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model name\n",
    "model_name = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load roberta tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a preprocessing function to tokenize text and truncate sequences to be no longer than roberta maximum input lengh\n",
    "def preprocess_function(df):\n",
    "    return tokenizer(df[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/22021108Cristina/.cache/huggingface/datasets/csv/default-7e50772f604fcc87/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-fc8a92f23e652bde.arrow\n"
     ]
    }
   ],
   "source": [
    "# apply the preprocessing function to the train dataset\n",
    "tokenized_train = train.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e998bb466c054a768c2603d401e9250f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name)#, num_labels=2, id2label=id2label, label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:717\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 717\u001b[0m     tensor \u001b[39m=\u001b[39m as_tensor(value)\n\u001b[1;32m    719\u001b[0m     \u001b[39m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[39m# # at-least2d\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[39m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     \u001b[39m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     \u001b[39m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 15 at dim 1 (got 21)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_train \u001b[39m=\u001b[39m tokenizer(tokenized_train[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m output_train \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoded_train)\n\u001b[1;32m      3\u001b[0m scores \u001b[39m=\u001b[39m output_train\u001b[39m.\u001b[39mlogits\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2530\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2528\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2529\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2530\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2531\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2616\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2611\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2612\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2613\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2614\u001b[0m         )\n\u001b[1;32m   2615\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[0;32m-> 2616\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[1;32m   2617\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2618\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2619\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2620\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2621\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2622\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2623\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2624\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2625\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2626\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2627\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2628\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2629\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2630\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2631\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2632\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2633\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2634\u001b[0m     )\n\u001b[1;32m   2635\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2636\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2637\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2638\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2654\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2655\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2807\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2798\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2799\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2800\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2804\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2805\u001b[0m )\n\u001b[0;32m-> 2807\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[1;32m   2808\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2809\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2810\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2811\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2812\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2813\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2814\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2815\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2816\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2817\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2818\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2819\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2820\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2821\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2822\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2823\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2824\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2825\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:476\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39mfor\u001b[39;00m input_ids \u001b[39min\u001b[39;00m sanitized_tokens[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    475\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 476\u001b[0m \u001b[39mreturn\u001b[39;00m BatchEncoding(sanitized_tokens, sanitized_encodings, tensor_type\u001b[39m=\u001b[39;49mreturn_tensors)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    206\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[0;32m--> 210\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39;49mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:733\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moverflowing_tokens\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    729\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    730\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    732\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    734\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    735\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpadding=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtruncation=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    736\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m features (`\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "encoded_train = tokenizer(tokenized_train[\"train\"][\"text\"], return_tensors=\"pt\")\n",
    "output_train = model(**encoded_train)\n",
    "scores = output_train.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
