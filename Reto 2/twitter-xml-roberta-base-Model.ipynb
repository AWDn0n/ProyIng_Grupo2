{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBARIES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i really do recommend this to anyone in need o...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>very good every day camera fits nicely in the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>but , dollar for dollar , this dvd player is p...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_idx                                               text  label  \\\n",
       "0          0  i really do recommend this to anyone in need o...      1   \n",
       "1          1  very good every day camera fits nicely in the ...      1   \n",
       "2          2  but , dollar for dollar , this dvd player is p...      1   \n",
       "\n",
       "  label_text  \n",
       "0   positive  \n",
       "1   positive  \n",
       "2   positive  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fm receiver it has none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the picture quality surprised me , when i firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>great video clip quality for a digital camera ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_idx                                               text\n",
       "0         0                            fm receiver it has none\n",
       "1         1  the picture quality surprised me , when i firs...\n",
       "2         2  great video clip quality for a digital camera ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_idx     0\n",
       "text          0\n",
       "label         0\n",
       "label_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any colulumn has null values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_idx    0\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1926\n",
       "0    1090\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"label\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train data into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_split, val_split = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a bit disappoint on that ! \n",
      " [{'label': 'positive', 'score': 0.7560573816299438}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_task = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path)\n",
    "print(test['text'][np.random.randint(0, len(test))], \"\\n\", sentiment_task(test['text'][np.random.randint(0, len(test))]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 2e-5\n",
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "#MODEL = \"cardiffnlp/twitter-xlm-roberta-base\" # use this to finetune the language model\n",
    "MODEL = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\" # use this to finetune the sentiment classifier\n",
    "MAX_TRAINING_EXAMPLES = -1 # set this to -1 if you want to use the whole training set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_split['text'].tolist(), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_split['text'].tolist(), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MyDataset(train_encodings, train_split[\"text\"])\n",
    "val_dataset = MyDataset(val_encodings, val_split[\"text\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE-TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'text', 'labels'],\n",
       "        num_rows: 3016\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/22021108Cristina/.cache/huggingface/datasets/csv/default-7e50772f604fcc87/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f2070f9e1a4f90917331963c590532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = load_dataset('csv', data_files='data/train.csv')\n",
    "# have in the train DatasetDict only the columns \"train_idx\", \"text\" and \"label\"\n",
    "train = train.remove_columns(\"label_text\")\n",
    "train = train.rename_column(\"train_idx\", \"input_ids\") # rename the \"train_idx\" column back to \"input_ids\" for compatibility with the model\n",
    "train = train.rename_column(\"label\", \"labels\") # rename the \"label\" column back to \"labels\" for compatibility with the model\n",
    "\n",
    "\n",
    "# Tokenize your dataset\n",
    "tokenized_dataset = tokenizer(\n",
    "    list(train[\"train\"][\"text\"]),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    ")\n",
    "# Add labels to the tokenized dataset\n",
    "tokenized_dataset[\"labels\"] = list(train[\"train\"][\"labels\"])\n",
    "# input_ids: this colum contains the tokenized input sequences converted into their corresponding numerical IDs.\n",
    "# labels: this column contains the target labelsthat you want your model to predict for each input sequence.\n",
    "# attention_mark: this column contains the attention mask that you will use to tell the model which tokens are actual words and which are padding tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[\"attention_mask\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3016\n",
      "3016\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_dataset[\"input_ids\"]))\n",
    "print(len(tokenized_dataset[\"attention_mask\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/22021108Cristina/.cache/huggingface/datasets/csv/default-7e50772f604fcc87/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "/home/22021108Cristina/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,token_type_ids,position_ids,head_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,label_ids,labels,label.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 44\u001b[0m\n\u001b[1;32m     27\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m     28\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./models/2.twitter-xml-roberta-base/\u001b[39m\u001b[39m'\u001b[39m,          \u001b[39m# output directory\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     evaluation_strategy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,   \u001b[39m# evaluate model after each epoch\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     push_to_hub\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     39\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     40\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m     41\u001b[0m     train_dataset\u001b[39m=\u001b[39mtokenized_dataset\n\u001b[1;32m     42\u001b[0m )\n\u001b[0;32m---> 44\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1632\u001b[0m )\n\u001b[0;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1638\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1900\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1901\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1902\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1905\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1906\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1907\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1908\u001b[0m ):\n\u001b[1;32m   1909\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2638\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2620\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2621\u001b[0m \u001b[39mPerform a training step on a batch of inputs.\u001b[39;00m\n\u001b[1;32m   2622\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[39m    `torch.Tensor`: The tensor with training loss on this batch.\u001b[39;00m\n\u001b[1;32m   2636\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2637\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m-> 2638\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_inputs(inputs)\n\u001b[1;32m   2640\u001b[0m \u001b[39mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2641\u001b[0m     loss_mb \u001b[39m=\u001b[39m smp_forward_backward(model, inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2585\u001b[0m, in \u001b[0;36mTrainer._prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2583\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_input(inputs)\n\u001b[1;32m   2584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2585\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2586\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe batch received was empty, your model won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be able to train on it. Double-check that your \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2587\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtraining dataset contains keys expected by the model: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signature_columns)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_past \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2590\u001b[0m     inputs[\u001b[39m\"\u001b[39m\u001b[39mmems\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_past\n",
      "\u001b[0;31mValueError\u001b[0m: The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: input_ids,attention_mask,token_type_ids,position_ids,head_mask,inputs_embeds,labels,output_attentions,output_hidden_states,return_dict,label_ids,labels,label."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, return_token_type_ids=False)\n",
    "\n",
    "# Load the train dataset\n",
    "train = load_dataset('csv', data_files='data/train.csv', split='train')\n",
    "\n",
    "# Tokenize the input text\n",
    "tokenized_dataset = tokenizer(\n",
    "    list(train['text']),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Add labels to the tokenized dataset\n",
    "labels = [int(l) for l in train['label']]\n",
    "tokenized_dataset['label'] = labels\n",
    "\n",
    "# Train the model on the tokenized dataset\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./models/2.twitter-xml-roberta-base/',          # output directory\n",
    "    evaluation_strategy = \"epoch\",   # evaluate model after each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'label'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/22021108Cristina/.cache/huggingface/datasets/csv/default-7e50772f604fcc87/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b004e31c463d4a1cb14df6b6e1fd469d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276550b764e54659a92c690694406e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3016 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='567' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 48/567 00:04 < 00:55, 9.34 it/s, Epoch 0.25/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Trainer: evaluation requires an eval_dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 35\u001b[0m\n\u001b[1;32m     18\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m     19\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmy_finetuned_model\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     evaluation_strategy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     push_to_hub\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     30\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     31\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m     32\u001b[0m     train_dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1632\u001b[0m )\n\u001b[0;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1638\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1994\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1991\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1994\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1996\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[1;32m   1997\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1998\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2236\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2230\u001b[0m             metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m   2231\u001b[0m                 eval_dataset\u001b[39m=\u001b[39meval_dataset,\n\u001b[1;32m   2232\u001b[0m                 ignore_keys\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2233\u001b[0m                 metric_key_prefix\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meval_\u001b[39m\u001b[39m{\u001b[39;00meval_dataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2234\u001b[0m             )\n\u001b[1;32m   2235\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2236\u001b[0m         metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[1;32m   2237\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2239\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2928\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2925\u001b[0m \u001b[39m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m   2926\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_memory_tracker\u001b[39m.\u001b[39mstart()\n\u001b[0;32m-> 2928\u001b[0m eval_dataloader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_eval_dataloader(eval_dataset)\n\u001b[1;32m   2929\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2931\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:935\u001b[0m, in \u001b[0;36mTrainer.get_eval_dataloader\u001b[0;34m(self, eval_dataset)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[39mReturns the evaluation [`~torch.utils.data.DataLoader`].\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39m        by the `model.forward()` method are automatically removed. It must implement `__len__`.\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m eval_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrainer: evaluation requires an eval_dataset.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    936\u001b[0m eval_dataset \u001b[39m=\u001b[39m eval_dataset \u001b[39mif\u001b[39;00m eval_dataset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dataset\n\u001b[1;32m    937\u001b[0m data_collator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_collator\n",
      "\u001b[0;31mValueError\u001b[0m: Trainer: evaluation requires an eval_dataset."
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, ignore_mismatched_sizes=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = load_dataset('csv', data_files='data/train.csv')['train']\n",
    "\n",
    "# Tokenize your dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], truncation=True, padding=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "\n",
    "# Train the model on your dataset\n",
    "training_args = TrainingArguments(\n",
    "    \"my_finetuned_model\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer and the model\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = torch.load(\"train_dataset.pt\")\n",
    "eval_dataset = torch.load(\"eval_dataset.pt\")\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    save_total_limit=3,\n",
    "    save_steps=500,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e998bb466c054a768c2603d401e9250f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name)#, num_labels=2, id2label=id2label, label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:717\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 717\u001b[0m     tensor \u001b[39m=\u001b[39m as_tensor(value)\n\u001b[1;32m    719\u001b[0m     \u001b[39m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[39m# # at-least2d\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[39m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     \u001b[39m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    724\u001b[0m     \u001b[39m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 15 at dim 1 (got 21)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoded_train \u001b[39m=\u001b[39m tokenizer(tokenized_train[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m], return_tensors\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m output_train \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoded_train)\n\u001b[1;32m      3\u001b[0m scores \u001b[39m=\u001b[39m output_train\u001b[39m.\u001b[39mlogits\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2530\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2528\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2529\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2530\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2531\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2616\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2611\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2612\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2613\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2614\u001b[0m         )\n\u001b[1;32m   2615\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[0;32m-> 2616\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[1;32m   2617\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2618\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2619\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2620\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2621\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2622\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2623\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2624\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2625\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2626\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2627\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2628\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2629\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2630\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2631\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2632\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2633\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2634\u001b[0m     )\n\u001b[1;32m   2635\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2636\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2637\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2638\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2654\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2655\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2807\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2798\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2799\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2800\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2804\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2805\u001b[0m )\n\u001b[0;32m-> 2807\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[1;32m   2808\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2809\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2810\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2811\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2812\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2813\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2814\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2815\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2816\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2817\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2818\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2819\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2820\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2821\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2822\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2823\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2824\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2825\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:476\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39mfor\u001b[39;00m input_ids \u001b[39min\u001b[39;00m sanitized_tokens[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    475\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 476\u001b[0m \u001b[39mreturn\u001b[39;00m BatchEncoding(sanitized_tokens, sanitized_encodings, tensor_type\u001b[39m=\u001b[39;49mreturn_tensors)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:210\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    206\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[1;32m    208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[0;32m--> 210\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39;49mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:733\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moverflowing_tokens\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    729\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    730\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    732\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    734\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    735\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpadding=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtruncation=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    736\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m features (`\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "encoded_train = tokenizer(tokenized_train[\"train\"][\"text\"], return_tensors=\"pt\")\n",
    "output_train = model(**encoded_train)\n",
    "scores = output_train.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
